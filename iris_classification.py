# Iris Flower Classification Project
# ‡∂∏‡∂Ω‡∑ä ‡∑Ä‡∂ª‡∑ä‡∂ú ‡∑Ä‡∂ª‡∑ä‡∂ú‡∑ì‡∂ö‡∂ª‡∂´ ‡∑Ä‡∑ä‚Äç‡∂∫‡∑è‡∂¥‡∑ò‡∂≠‡∑í‡∂∫

# Step 1: Import ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂ï‡∂± libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 2: Dataset ‡∂ë‡∂ö load ‡∂ö‡∂ª‡∂±‡∑ä‡∂±
print("=" * 50)
print("Dataset Loading (‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏)")
print("=" * 50)

iris = load_iris()
X = iris.data  # Features (‡∑Ä‡∑í‡∑Å‡∑ö‡∑Ç‡∑è‡∂Ç‡∂ú) - sepal length, sepal width, petal length, petal width

# print(f"\nFeatures: {X}")
y = iris.target  # Target (‡∂â‡∂Ω‡∂ö‡∑ä‡∂ö‡∂∫) - flower type (0, 1, 2)
print(f"\nFeatures: {y}")
# DataFrame ‡∂ë‡∂ö‡∂ö‡∑ä ‡∑Ñ‡∂Ø‡∂±‡∑ä‡∂± - easy visualization ‡∑Ä‡∂Ω‡∂ß
df = pd.DataFrame(X, columns=iris.feature_names)
df['species'] = iris.target
df['species_name'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})

print(f"\nDataset Shape: {df.shape}")
print(f"Total Samples (‡∂∏‡∑î‡∑Ö‡∑î ‡∂±‡∑í‡∂∫‡∑ê‡∂Ø‡∑í): {len(df)}")
print(f"\nFirst 5 rows:\n{df.head()}")

# Step 3: Data Exploration (‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∑Ä‡∑í‡∑Å‡∑ä‡∂Ω‡∑ö‡∑Ç‡∂´‡∂∫)
print("\n" + "=" * 50)
print("Data Exploration")
print("=" * 50)

print("\nBasic Statistics (‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∑É‡∂Ç‡∂õ‡∑ä‚Äç‡∂∫‡∑è‡∂±):")
print(df.describe())

print("\nSpecies Distribution (‡∂∏‡∂Ω‡∑ä ‡∑Ä‡∂ª‡∑ä‡∂ú ‡∑Ä‡∑ä‚Äç‡∂∫‡∑è‡∂¥‡∑ä‡∂≠‡∑í‡∂∫):")
print(df['species_name'].value_counts())

print("\nMissing Values (‡∂±‡∑ê‡∂≠‡∑í ‡∂Ö‡∂ú‡∂∫‡∂±‡∑ä):")
print(df.isnull().sum())

# Step 4: Data Visualization (‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∂±‡∑í‡∂ª‡∑ñ‡∂¥‡∂´‡∂∫)
print("\n" + "=" * 50)
print("Creating Visualizations (‡∂†‡∑í‡∂≠‡∑ä‚Äç‡∂ª ‡∂±‡∑í‡∂ª‡∑ä‡∂∏‡∑è‡∂´‡∂∫)")
print("=" * 50)

# Pairplot - Features ‡∂ë‡∂ö‡∑í‡∂±‡∑ô‡∂ö‡∂ß ‡∑É‡∂Ç‡∑É‡∂±‡∑ä‡∂Ø‡∂±‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏
plt.figure(figsize=(12, 10))
sns.pairplot(df, hue='species_name', markers=['o', 's', 'D'])
plt.suptitle('Iris Dataset - Feature Relationships', y=1.02)
plt.tight_layout()
plt.savefig('iris_pairplot.png', dpi=300, bbox_inches='tight')
print("‚úì Pairplot saved as 'iris_pairplot.png'")

# Correlation Matrix (‡∑É‡∑Ñ‡∑É‡∂∏‡∑ä‡∂∂‡∂±‡∑ä‡∂∞‡∂≠‡∑è ‡∂±‡∑ä‚Äç‡∂∫‡∑è‡∑É‡∂∫)
plt.figure(figsize=(10, 8))
correlation = df.iloc[:, :-2].corr()
sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)
plt.title('Feature Correlation Matrix')
plt.tight_layout()
plt.savefig('iris_correlation.png', dpi=300, bbox_inches='tight')
print("‚úì Correlation matrix saved as 'iris_correlation.png'")

# Step 5: Data Preparation (‡∂Ø‡∂≠‡∑ä‡∂≠ ‡∑É‡∂ö‡∑É‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏)
print("\n" + "=" * 50)
print("Data Preparation for Training")
print("=" * 50)

# Train-Test Split (‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î-‡∂¥‡∂ª‡∑ì‡∂ö‡∑ä‡∑Ç‡∂´ ‡∂∂‡∑ô‡∂Ø‡∑ì‡∂∏)
# 80% training, 20% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Training samples (‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î ‡∂±‡∑í‡∂∫‡∑ê‡∂Ø‡∑í): {len(X_train)}")
print(f"Testing samples (‡∂¥‡∂ª‡∑ì‡∂ö‡∑ä‡∑Ç‡∂´ ‡∂±‡∑í‡∂∫‡∑ê‡∂Ø‡∑í): {len(X_test)}")

# Feature Scaling (‡∑Ä‡∑í‡∑Å‡∑ö‡∑Ç‡∑è‡∂Ç‡∂ú ‡∂¥‡∂ª‡∑í‡∂∏‡∑è‡∂´‡∂ö‡∂ª‡∂´‡∂∫)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("‚úì Data scaled successfully")

# Step 6: Model Training (‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏)
print("\n" + "=" * 50)
print("Training Multiple Models (‡∂∂‡∑Ñ‡∑î ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏)")
print("=" * 50)

models = {
    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=3),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Support Vector Machine': SVC(kernel='rbf', random_state=42)
}

results = {}

for name, model in models.items():
    print(f"\nTraining {name}...")
    
    # Model train ‡∂ö‡∂ª‡∂±‡∑ä‡∂±
    model.fit(X_train_scaled, y_train)
    
    # Predictions (‡∂Ö‡∂±‡∑è‡∑Ä‡∑ê‡∂ö‡∑í)
    y_pred = model.predict(X_test_scaled)
    
    # Accuracy (‡∂±‡∑í‡∂ª‡∑Ä‡∂Ø‡∑ä‚Äç‡∂∫‡∂≠‡∑è‡∑Ä‡∂∫)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy
    
    print(f"‚úì {name} Accuracy: {accuracy * 100:.2f}%")
    
    # Detailed Report
    print(f"\nClassification Report for {name}:")
    print(classification_report(y_test, y_pred, target_names=iris.target_names))

# Step 7: Results Comparison (‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂µ‡∂Ω ‡∑É‡∂Ç‡∑É‡∂±‡∑ä‡∂Ø‡∂±‡∂∫)
print("\n" + "=" * 50)
print("Model Comparison (‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í ‡∑É‡∂Ç‡∑É‡∂±‡∑ä‡∂Ø‡∂±‡∂∫)")
print("=" * 50)

for name, accuracy in results.items():
    print(f"{name}: {accuracy * 100:.2f}%")

# Best Model
best_model = max(results, key=results.get)
print(f"\nüèÜ Best Model: {best_model} with {results[best_model] * 100:.2f}% accuracy")

# Visualize Model Comparison
plt.figure(figsize=(10, 6))
plt.bar(results.keys(), [acc * 100 for acc in results.values()], color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
plt.xlabel('Models (‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í)')
plt.ylabel('Accuracy % (‡∂±‡∑í‡∂ª‡∑Ä‡∂Ø‡∑ä‚Äç‡∂∫‡∂≠‡∑è‡∑Ä‡∂∫)')
plt.title('Model Performance Comparison')
plt.ylim(90, 100)
for i, (name, acc) in enumerate(results.items()):
    plt.text(i, acc * 100 + 0.5, f'{acc * 100:.2f}%', ha='center')
plt.tight_layout()
plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')
print("\n‚úì Model comparison chart saved as 'model_comparison.png'")

# Step 8: Confusion Matrix (‡∑Ä‡∑ä‚Äç‡∂∫‡∑è‡∂ö‡∑ñ‡∂Ω‡∂≠‡∑è ‡∂±‡∑ä‚Äç‡∂∫‡∑è‡∑É‡∂∫)
print("\n" + "=" * 50)
print("Confusion Matrix for Best Model")
print("=" * 50)

best_model_obj = models[best_model]
y_pred_best = best_model_obj.predict(X_test_scaled)
cm = confusion_matrix(y_test, y_pred_best)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.xlabel('Predicted (‡∂Ö‡∂±‡∑è‡∑Ä‡∑ê‡∂ö‡∑í ‡∂ö‡∑Ö)')
plt.ylabel('Actual (‡∑É‡∑ê‡∂∂‡∑ë)')
plt.title(f'Confusion Matrix - {best_model}')
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
print("‚úì Confusion matrix saved as 'confusion_matrix.png'")

# Step 9: Make Predictions (‡∂Ö‡∂Ω‡∑î‡∂≠‡∑ä ‡∂Ö‡∂±‡∑è‡∑Ä‡∑ê‡∂ö‡∑í ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏)
print("\n" + "=" * 50)
print("Making New Predictions (‡∂Ö‡∂Ω‡∑î‡∂≠‡∑ä ‡∂Ö‡∂±‡∑è‡∑Ä‡∑ê‡∂ö‡∑í)")
print("=" * 50)

# Example: ‡∂±‡∑Ä ‡∂∏‡∂Ω‡∂ö‡∑ä predict ‡∂ö‡∂ª‡∂±‡∑ä‡∂±
new_flower = np.array([[5.1, 3.5, 1.4, 0.2]])  # Sample measurements
new_flower_scaled = scaler.transform(new_flower)
prediction = best_model_obj.predict(new_flower_scaled)
predicted_species = iris.target_names[prediction[0]]

print(f"New Flower Measurements: {new_flower[0]}")
print(f"Predicted Species (‡∂Ö‡∂±‡∑è‡∑Ä‡∑ê‡∂ö‡∑í ‡∂ö‡∑Ö ‡∂∏‡∂Ω‡∑ä ‡∑Ä‡∂ª‡∑ä‡∂ú‡∂∫): {predicted_species}")

print("\n" + "=" * 50)
print("Project Completed Successfully! ‚ú®")
print("=" * 50)